{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9XRCyI+lCz25JMqOUBu2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaofangZH/Segment-Anything-2-AGV-Test/blob/main/CRNN_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "veVyOm_Skbwy"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# zip_path='/content/sample_data/train_crnn.zip'\n",
        "# extract_path='/content/sample_data/'\n",
        "# with zipfile.ZipFile(zip_path) as zip_ref:\n",
        "#   zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "# gen alphabet via label\n",
        "# alphabet_set = set()\n",
        "# infofiles = ['train_data/train/train.txt']\n",
        "# for infofile in infofiles:\n",
        "#     f = open(infofile)\n",
        "#     content = f.readlines()\n",
        "#     f.close()\n",
        "#     for line in content:\n",
        "#         if len(line.strip())>0:\n",
        "#             if len(line.strip().split('jpg'))!=2:\n",
        "#                 print(line)\n",
        "#             else:\n",
        "#                 fname,label = line.strip().split('jpg')\n",
        "#                 fname+='jpg'\n",
        "#                 for ch in label:\n",
        "#                     alphabet_set.add(ch)\n",
        "# alphabet_list = sorted(list(alphabet_set))\n",
        "# pkl.dump(alphabet_list,open('alphabet.pkl','wb'))\n",
        "\n",
        "alphabet_list = pkl.load(open('/content/sample_data/train_crnn/alphabet.pkl','rb'))\n",
        "alphabet = [ord(ch) for ch in alphabet_list]\n",
        "alphabet_v2 = alphabet"
      ],
      "metadata": {
        "id": "VKLPl60SrD-M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_infofile = '/content/sample_data/train_crnn/train_data/'\n",
        "train_infofile_fullimg = ''\n",
        "val_infofile = '/content/sample_data/train_crnn/train_data/train/test.txt'\n",
        "alphabet = alphabet\n",
        "alphabet_v2 = alphabet_v2\n",
        "workers = 4\n",
        "batchSize = 50\n",
        "imgH = 32\n",
        "imgW = 280\n",
        "nc = 1\n",
        "nclass = len(alphabet)+1\n",
        "nh = 256\n",
        "niter = 100\n",
        "lr = 0.0003\n",
        "beta1 = 0.5\n",
        "cuda = True\n",
        "ngpu = 1\n",
        "pretrained_model = '/content/sample_data/train_crnn/crnn_models/E-Point-Super.pth'\n",
        "saved_model_dir = '/content/sample_data/train_crnn/crnn_models'\n",
        "saved_model_prefix = 'CRNN-'\n",
        "use_log = False\n",
        "remove_blank = False\n",
        "\n",
        "experiment = None\n",
        "displayInterval = 500\n",
        "n_test_disp = 10\n",
        "valInterval = 500\n",
        "saveInterval = 500\n",
        "adam = False\n",
        "adadelta = False\n",
        "keep_ratio = False\n",
        "random_sample = True"
      ],
      "metadata": {
        "id": "ZOSUzJCGrUVD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "class BidirectionalLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, nIn, nHidden, nOut):\n",
        "        super(BidirectionalLSTM, self).__init__()\n",
        "\n",
        "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
        "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
        "\n",
        "    def forward(self, input):\n",
        "        recurrent, _ = self.rnn(input)\n",
        "        T, b, h = recurrent.size()\n",
        "        t_rec = recurrent.view(T * b, h)\n",
        "\n",
        "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
        "        output = output.view(T, b, -1)\n",
        "        return output\n",
        "\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, imgH, nc, nclass, nh, leakyRelu=False):\n",
        "        super(CRNN, self).__init__()\n",
        "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
        "\n",
        "        # 1x32x128\n",
        "        self.conv1 = nn.Conv2d(nc, 64, 3, 1, 1)\n",
        "        self.relu1 = nn.ReLU(True)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # 64x16x64\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.relu2 = nn.ReLU(True)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # 128x8x32\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.relu3_1 = nn.ReLU(True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.relu3_2 = nn.ReLU(True)\n",
        "        self.pool3 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
        "\n",
        "        # 256x4x16\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, 1, 1)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.relu4_1 = nn.ReLU(True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "        self.relu4_2 = nn.ReLU(True)\n",
        "        self.pool4 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
        "\n",
        "        # 512x2x16\n",
        "        self.conv5 = nn.Conv2d(512, 512, 2, 1, 0)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.relu5 = nn.ReLU(True)\n",
        "\n",
        "        # 512x1x16\n",
        "\n",
        "        self.rnn = nn.Sequential(\n",
        "            BidirectionalLSTM(512, nh, nh),\n",
        "            BidirectionalLSTM(nh, nh, nclass))\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        # conv features\n",
        "        print('1:',input.size())\n",
        "        x = self.pool1(self.relu1(self.conv1(input)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.pool3(self.relu3_2(self.conv3_2(self.relu3_1(self.bn3(self.conv3_1(x))))))\n",
        "        x = self.pool4(self.relu4_2(self.conv4_2(self.relu4_1(self.bn4(self.conv4_1(x))))))\n",
        "        conv = self.relu5(self.bn5(self.conv5(x)))\n",
        "        print('2:',conv.size())\n",
        "\n",
        "        b, c, h, w = conv.size()\n",
        "        assert h == 1, \"the height of conv must be 1\"\n",
        "        conv = conv.squeeze(2)\n",
        "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
        "        print('3:',conv.size())\n",
        "        # rnn features\n",
        "        output = self.rnn(conv)\n",
        "        print('4:',output.size())\n",
        "        return output\n",
        "\n",
        "\n",
        "class CRNN_v2(nn.Module):\n",
        "\n",
        "    def __init__(self, imgH, nc, nclass, nh, leakyRelu=False):\n",
        "        super(CRNN_v2, self).__init__()\n",
        "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
        "\n",
        "        # 1x32x128\n",
        "        self.conv1_1 = nn.Conv2d(nc, 32, 3, 1, 1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(32)\n",
        "        self.relu1_1 = nn.ReLU(True)\n",
        "\n",
        "        self.conv1_2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "        self.bn1_2 = nn.BatchNorm2d(64)\n",
        "        self.relu1_2 = nn.ReLU(True)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # 64x16x64\n",
        "        self.conv2_1 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(64)\n",
        "        self.relu2_1 = nn.ReLU(True)\n",
        "\n",
        "        self.conv2_2 = nn.Conv2d(64, 128, 3, 1, 1)\n",
        "        self.bn2_2 = nn.BatchNorm2d(128)\n",
        "        self.relu2_2 = nn.ReLU(True)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # 128x8x32\n",
        "        self.conv3_1 = nn.Conv2d(128, 96, 3, 1, 1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(96)\n",
        "        self.relu3_1 = nn.ReLU(True)\n",
        "\n",
        "        self.conv3_2 = nn.Conv2d(96, 192, 3, 1, 1)\n",
        "        self.bn3_2 = nn.BatchNorm2d(192)\n",
        "        self.relu3_2 = nn.ReLU(True)\n",
        "        self.pool3 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
        "\n",
        "        # 192x4x32\n",
        "        self.conv4_1 = nn.Conv2d(192, 128, 3, 1, 1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(128)\n",
        "        self.relu4_1 = nn.ReLU(True)\n",
        "        self.conv4_2 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.bn4_2 = nn.BatchNorm2d(256)\n",
        "        self.relu4_2 = nn.ReLU(True)\n",
        "        self.pool4 = nn.MaxPool2d((2, 2), (2, 1), (0, 1))\n",
        "\n",
        "        # 256x2x32\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "\n",
        "\n",
        "        # 256x2x32\n",
        "\n",
        "        self.rnn = nn.Sequential(\n",
        "            BidirectionalLSTM(512, nh, nh),\n",
        "            BidirectionalLSTM(nh, nh, nclass))\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        # conv features\n",
        "        x = self.pool1(self.relu1_2(self.bn1_2(self.conv1_2(self.relu1_1(self.bn1_1(self.conv1_1(input)))))))\n",
        "        x = self.pool2(self.relu2_2(self.bn2_2(self.conv2_2(self.relu2_1(self.bn2_1(self.conv2_1(x)))))))\n",
        "        x = self.pool3(self.relu3_2(self.bn3_2(self.conv3_2(self.relu3_1(self.bn3_1(self.conv3_1(x)))))))\n",
        "        x = self.pool4(self.relu4_2(self.bn4_2(self.conv4_2(self.relu4_1(self.bn4_1(self.conv4_1(x)))))))\n",
        "        conv = self.bn5(x)\n",
        "        # print(conv.size())\n",
        "\n",
        "        b, c, h, w = conv.size()\n",
        "        assert h == 2, \"the height of conv must be 2\"\n",
        "        conv = conv.reshape([b,c*h,w])\n",
        "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
        "\n",
        "        # rnn features\n",
        "        output = self.rnn(conv)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def conv3x3(nIn, nOut, stride=1):\n",
        "    # \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d( nIn, nOut, kernel_size=3, stride=stride, padding=1, bias=False )\n",
        "\n",
        "\n",
        "class basic_res_block(nn.Module):\n",
        "\n",
        "    def __init__(self, nIn, nOut, stride=1, downsample=None):\n",
        "        super( basic_res_block, self ).__init__()\n",
        "        m = OrderedDict()\n",
        "        m['conv1'] = conv3x3( nIn, nOut, stride )\n",
        "        m['bn1'] = nn.BatchNorm2d( nOut )\n",
        "        m['relu1'] = nn.ReLU( inplace=True )\n",
        "        m['conv2'] = conv3x3( nOut, nOut )\n",
        "        m['bn2'] = nn.BatchNorm2d( nOut )\n",
        "        self.group1 = nn.Sequential( m )\n",
        "\n",
        "        self.relu = nn.Sequential( nn.ReLU( inplace=True ) )\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample( x )\n",
        "        else:\n",
        "            residual = x\n",
        "        out = self.group1( x ) + residual\n",
        "        out = self.relu( out )\n",
        "        return out\n",
        "\n",
        "\n",
        "class CRNN_res(nn.Module):\n",
        "\n",
        "    def __init__(self, imgH, nc, nclass, nh):\n",
        "        super(CRNN_res, self).__init__()\n",
        "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
        "\n",
        "        self.conv1 = nn.Conv2d(nc, 64, 3, 1, 1)\n",
        "        self.relu1 = nn.ReLU(True)\n",
        "        self.res1 = basic_res_block(64, 64)\n",
        "        # 1x32x128\n",
        "\n",
        "        down1 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),nn.BatchNorm2d(128))\n",
        "        self.res2_1 = basic_res_block( 64, 128, 2, down1 )\n",
        "        self.res2_2 = basic_res_block(128,128)\n",
        "        # 64x16x64\n",
        "\n",
        "        down2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),nn.BatchNorm2d(256))\n",
        "        self.res3_1 = basic_res_block(128, 256, 2, down2)\n",
        "        self.res3_2 = basic_res_block(256, 256)\n",
        "        self.res3_3 = basic_res_block(256, 256)\n",
        "        # 128x8x32\n",
        "\n",
        "        down3 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=1, stride=(2, 1), bias=False),nn.BatchNorm2d(512))\n",
        "        self.res4_1 = basic_res_block(256, 512, (2, 1), down3)\n",
        "        self.res4_2 = basic_res_block(512, 512)\n",
        "        self.res4_3 = basic_res_block(512, 512)\n",
        "        # 256x4x16\n",
        "\n",
        "        self.pool = nn.AvgPool2d((2, 2), (2, 1), (0, 1))\n",
        "        # 512x2x16\n",
        "\n",
        "        self.conv5 = nn.Conv2d(512, 512, 2, 1, 0)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.relu5 = nn.ReLU(True)\n",
        "        # 512x1x16\n",
        "\n",
        "        self.rnn = nn.Sequential(\n",
        "            BidirectionalLSTM(512, nh, nh),\n",
        "            BidirectionalLSTM(nh, nh, nclass))\n",
        "\n",
        "    def forward(self, input):\n",
        "        # conv features\n",
        "        x = self.res1(self.relu1(self.conv1(input)))\n",
        "        x = self.res2_2(self.res2_1(x))\n",
        "        x = self.res3_3(self.res3_2(self.res3_1(x)))\n",
        "        x = self.res4_3(self.res4_2(self.res4_1(x)))\n",
        "        x = self.pool(x)\n",
        "        conv = self.relu5(self.bn5(self.conv5(x)))\n",
        "        # print(conv.size())\n",
        "        b, c, h, w = conv.size()\n",
        "        assert h == 1, \"the height of conv must be 1\"\n",
        "        conv = conv.squeeze(2)\n",
        "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
        "\n",
        "        # rnn features\n",
        "        output = self.rnn(conv)\n",
        "\n",
        "        return output\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "Oase3XrGruOv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "import shutil\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageChops\n",
        "import cv2\n",
        "import numpy as np\n",
        "# import pyblur\n",
        "import PIL\n",
        "from PIL import Image, ImageEnhance\n",
        "# import\n",
        "import abc\n",
        "import time, datetime, inspect\n",
        "import hashlib\n",
        "import json\n",
        "import math\n",
        "\n",
        "\n",
        "def rename(filepath):\n",
        "    # print(f'rename {filepath} to 00X')\n",
        "    filelist = os.listdir(filepath)\n",
        "    filelist.sort()\n",
        "    i = 1\n",
        "    for filename in filelist:\n",
        "        if str(filename) == '.DS_Store':\n",
        "            continue\n",
        "        ext = filename.split('.')[-1]\n",
        "        shutil.move(filepath + '/' + filename, filepath + '/' + str(i).zfill(3) + '.' + ext)\n",
        "        i += 1\n",
        "\n",
        "\n",
        "def zlog(func):\n",
        "    def new_fn(*args):\n",
        "        start = time.time()\n",
        "        result = func(*args)\n",
        "        end = time.time()\n",
        "        duration = end - start\n",
        "        duration = \"%.4f\" % duration\n",
        "        # fulltime = time.strftime(\"%Y-%m-%d %H:%M:%S %f\", time.localtime())\n",
        "        fulltime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')\n",
        "        # print(f'{fulltime} {__file__} {func.__name__}:{inspect.getsourcelines(func)[-1]} cost: {duration}s',\n",
        "        #       sep=' ', end='\\n', file=sys.stdout, flush=False)\n",
        "        return result\n",
        "\n",
        "    return new_fn\n",
        "\n",
        "\n",
        "def getpilimage(image):\n",
        "    if isinstance(image, PIL.Image.Image):  # or isinstance(image, PIL.JpegImagePlugin.JpegImageFile):\n",
        "        return image\n",
        "    elif isinstance(image, np.ndarray):\n",
        "        return cv2pil(image)\n",
        "\n",
        "\n",
        "def getcvimage(image):\n",
        "    if isinstance(image, np.ndarray):\n",
        "        return image\n",
        "    elif isinstance(image, PIL.Image.Image):  # or isinstance(image, PIL.JpegImagePlugin.JpegImageFile):\n",
        "        return pil2cv(image)\n",
        "\n",
        "\n",
        "def cshowone(image):\n",
        "    image = getcvimage(image)\n",
        "    cv2.imshow('tmp', image)\n",
        "    cv2.waitKey(3000)\n",
        "    return\n",
        "\n",
        "\n",
        "def pshowone(image):\n",
        "    image = getpilimage(image)\n",
        "    image.show()\n",
        "    return\n",
        "\n",
        "\n",
        "def cshowtwo(image1, image2):\n",
        "    width = 800 / 2\n",
        "    height = 500 / 2\n",
        "    image1 = getpilimage(image1)\n",
        "    image2 = getpilimage(image2)\n",
        "    h, w = image1.size\n",
        "    image1 = image1.resize((int(width), int(h * height / w)))\n",
        "    image2 = image2.resize(image1.size)\n",
        "    bigimg = Image.new('RGB', (width * 2, image1.size[1]))\n",
        "\n",
        "    bigimg.paste(image1, (0, 0, image1.size[0], image1.size[1]))\n",
        "    bigimg.paste(image2, (width, 0, width + image1.size[0], image1.size[1]))\n",
        "    bigimg = getcvimage(bigimg)\n",
        "    cshowone(bigimg)\n",
        "    return\n",
        "\n",
        "\n",
        "def pshowtwo(image1, image2):\n",
        "    width = int(800 / 2)\n",
        "    height = int(500 / 2)\n",
        "    image1 = getpilimage(image1)\n",
        "    image2 = getpilimage(image2)\n",
        "    h, w = image1.size\n",
        "    image1 = image1.resize((int(width), int(h * height / w)))\n",
        "    image2 = image2.resize(image1.size)\n",
        "    bigimg = Image.new('RGB', (width * 2, image1.size[1]))\n",
        "\n",
        "    bigimg.paste(image1, (0, 0, image1.size[0], image1.size[1]))\n",
        "    bigimg.paste(image2, (width, 0, width + image1.size[0], image1.size[1]))\n",
        "    pshowone(bigimg)\n",
        "    return\n",
        "\n",
        "\n",
        "def pil2cv(image):\n",
        "    # assert isinstance(image, PIL.Image.Image) or isinstance(image,\n",
        "    #                                                         PIL.JpegImagePlugin.JpegImageFile), f'input image type is not PIL.image and is {type(\n",
        "    #     image)}'\n",
        "    if len(image.split()) == 1:\n",
        "        return np.asarray(image)\n",
        "    elif len(image.split()) == 3:\n",
        "        return cv2.cvtColor(np.asarray(image), cv2.COLOR_RGB2BGR)\n",
        "    elif len(image.split()) == 4:\n",
        "        return cv2.cvtColor(np.asarray(image), cv2.COLOR_RGBA2BGR)\n",
        "\n",
        "\n",
        "def cv2pil(image):\n",
        "    assert isinstance(image, np.ndarray), 'input image type is not cv2'\n",
        "    if len(image.shape) == 2:\n",
        "        return Image.fromarray(image)\n",
        "    elif len(image.shape) == 3:\n",
        "        return Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "def rgb2gray(filename):\n",
        "    im = Image.open(filename).convert('L')\n",
        "    im.show()\n",
        "\n",
        "    new_image = Image.new(\"L\", (im.width + 6, im.height + 6), 0)\n",
        "    out_image = Image.new(\"L\", (im.width + 6, im.height + 6), 0)\n",
        "\n",
        "    new_image.paste(im, (3, 3, im.width + 3, im.height + 3))\n",
        "\n",
        "    im = getcvimage(im)\n",
        "    new_image = getcvimage(new_image)\n",
        "    out_image = getcvimage(out_image)\n",
        "\n",
        "    _, thresh = cv2.threshold(new_image, 0, 255, cv2.THRESH_OTSU)\n",
        "    pshowone(thresh)\n",
        "    image, contours, hierarchy = cv2.findContours(thresh, 3, 2)\n",
        "    # cnt = contours[0]\n",
        "    # hull = cv2.convexHull(cnt)\n",
        "    # image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "    print(len(contours))\n",
        "    cv2.polylines(out_image, contours, True, 255)\n",
        "    # cv2.fillPoly(image, [cnt], 255)\n",
        "    image = getpilimage(out_image)\n",
        "    im = getpilimage(im)\n",
        "    image = image.crop((3, 3, im.width + 3, im.height + 3))\n",
        "    # char_color = image.crop((3,3,char_image.width + 3, char_image.height + 3))\n",
        "    image.show()\n",
        "    return\n",
        "\n",
        "\n",
        "def uniqueimg(filepath):\n",
        "    # print(f'unique {filepath}')\n",
        "    filepath += '/'\n",
        "    filelist = os.listdir(filepath)\n",
        "    filelist.sort()\n",
        "    i = 1\n",
        "    for filename in filelist:\n",
        "        if str(filename) == '.DS_Store':\n",
        "            continue\n",
        "        fd = np.array(Image.open(filepath + filename))\n",
        "        fmd5 = hashlib.md5(fd)\n",
        "        # print(fmd5.hexdigest())\n",
        "        # print(filename)\n",
        "        ext = filename.split('.')[-1]\n",
        "        shutil.move(filepath + filename, filepath + fmd5.hexdigest() + '.' + ext)\n",
        "        # i += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "Dl5tAE5hr0Ds"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "#coding:utf-8\n",
        "import sys\n",
        "# reload(sys)\n",
        "# sys.setdefaultencoding(\"utf-8\")\n",
        "import os, sys, shutil, math, random, json, multiprocessing, threading\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageChops\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
        "# import\n",
        "import abc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "global colormap\n",
        "index = 0\n",
        "\n",
        "class TransBase(object):\n",
        "    def __init__(self, probability = 1.):\n",
        "        super(TransBase, self).__init__()\n",
        "        self.probability = probability\n",
        "    @abc.abstractmethod\n",
        "    def tranfun(self, inputimage):\n",
        "        pass\n",
        "    # @utils.zlog\n",
        "    def process(self,inputimage):\n",
        "        if np.random.random() < self.probability:\n",
        "            return self.tranfun(inputimage)\n",
        "        else:\n",
        "            return inputimage\n",
        "\n",
        "class RandomContrast(TransBase):\n",
        "    def setparam(self, lower=0.5, upper=1.5):\n",
        "        self.lower = lower\n",
        "        self.upper = upper\n",
        "        assert self.upper >= self.lower, \"upper must be >= lower.\"\n",
        "        assert self.lower >= 0, \"lower must be non-negative.\"\n",
        "    def tranfun(self, image):\n",
        "        image = getpilimage(image)\n",
        "        enh_con = ImageEnhance.Brightness(image)\n",
        "        return enh_con.enhance(random.uniform(self.lower, self.upper))\n",
        "\n",
        "class RandomBrightness(TransBase):\n",
        "    def setparam(self, lower=0.5, upper=1.5):\n",
        "        self.lower = lower\n",
        "        self.upper = upper\n",
        "        assert self.upper >= self.lower, \"upper must be >= lower.\"\n",
        "        assert self.lower >= 0, \"lower must be non-negative.\"\n",
        "    def tranfun(self, image):\n",
        "        image = getpilimage(image)\n",
        "        bri = ImageEnhance.Brightness(image)\n",
        "        return bri.enhance(random.uniform(self.lower, self.upper))\n",
        "\n",
        "class RandomColor(TransBase):\n",
        "    def setparam(self, lower=0.5, upper=1.5):\n",
        "        self.lower = lower\n",
        "        self.upper = upper\n",
        "        assert self.upper >= self.lower, \"upper must be >= lower.\"\n",
        "        assert self.lower >= 0, \"lower must be non-negative.\"\n",
        "    def tranfun(self, image):\n",
        "        image = getpilimage(image)\n",
        "        col = ImageEnhance.Color(image)\n",
        "        return col.enhance(random.uniform(self.lower, self.upper))\n",
        "\n",
        "class RandomSharpness(TransBase):\n",
        "    def setparam(self, lower=0.5, upper=1.5):\n",
        "        self.lower = lower\n",
        "        self.upper = upper\n",
        "        assert self.upper >= self.lower, \"upper must be >= lower.\"\n",
        "        assert self.lower >= 0, \"lower must be non-negative.\"\n",
        "    def tranfun(self, image):\n",
        "        image = getpilimage(image)\n",
        "        sha = ImageEnhance.Sharpness(image)\n",
        "        return sha.enhance(random.uniform(self.lower, self.upper))\n",
        "\n",
        "class Compress(TransBase):\n",
        "    def setparam(self, lower=5, upper=85):\n",
        "        self.lower = lower\n",
        "        self.upper = upper\n",
        "        assert self.upper >= self.lower, \"upper must be >= lower.\"\n",
        "        assert self.lower >= 0, \"lower must be non-negative.\"\n",
        "    def tranfun(self, image):\n",
        "        img = getcvimage(image)\n",
        "        param = [int(cv2.IMWRITE_JPEG_QUALITY), random.randint(self.lower, self.upper)]\n",
        "        img_encode = cv2.imencode('.jpeg', img, param)\n",
        "        img_decode = cv2.imdecode(img_encode[1], cv2.IMREAD_COLOR)\n",
        "        pil_img = cv2pil(img_decode)\n",
        "        if len(image.split())==1:\n",
        "            pil_img = pil_img.convert('L')\n",
        "        return pil_img\n",
        "\n",
        "class Exposure(TransBase):\n",
        "    def setparam(self, lower=5, upper=10):\n",
        "        self.lower = lower\n",
        "        self.upper = upper\n",
        "        assert self.upper >= self.lower, \"upper must be >= lower.\"\n",
        "        assert self.lower >= 0, \"lower must be non-negative.\"\n",
        "    def tranfun(self, image):\n",
        "        image = getcvimage(image)\n",
        "        h,w = image.shape[:2]\n",
        "        x0 = random.randint(0, w)\n",
        "        y0 = random.randint(0, h)\n",
        "        x1 = random.randint(x0, w)\n",
        "        y1 = random.randint(y0, h)\n",
        "        transparent_area = (x0, y0, x1, y1)\n",
        "        mask=Image.new('L', (w, h), color=255)\n",
        "        draw=ImageDraw.Draw(mask)\n",
        "        mask = np.array(mask)\n",
        "        if len(image.shape)==3:\n",
        "            mask = mask[:,:,np.newaxis]\n",
        "            mask = np.concatenate([mask,mask,mask],axis=2)\n",
        "        draw.rectangle(transparent_area, fill=random.randint(150,255))\n",
        "        reflection_result = image + (255 - mask)\n",
        "        reflection_result = np.clip(reflection_result, 0, 255)\n",
        "        return cv2pil(reflection_result)\n",
        "\n",
        "class Rotate(TransBase):\n",
        "    def setparam(self, lower=-5, upper=5):\n",
        "        self.lower = lower\n",
        "        self.upper = upper\n",
        "        assert self.upper >= self.lower, \"upper must be >= lower.\"\n",
        "        # assert self.lower >= 0, \"lower must be non-negative.\"\n",
        "    def tranfun(self, image):\n",
        "        image = getpilimage(image)\n",
        "        rot = random.uniform(self.lower, self.upper)\n",
        "        trans_img = image.rotate(rot, expand=True)\n",
        "        # trans_img.show()\n",
        "        return trans_img\n",
        "\n",
        "class Blur(TransBase):\n",
        "    def setparam(self, lower=0, upper=1):\n",
        "        self.lower = lower\n",
        "        self.upper = upper\n",
        "        assert self.upper >= self.lower, \"upper must be >= lower.\"\n",
        "        assert self.lower >= 0, \"lower must be non-negative.\"\n",
        "    def tranfun(self, image):\n",
        "        image = getpilimage(image)\n",
        "        image = image.filter(ImageFilter.GaussianBlur(radius=1))\n",
        "        # blurred_image = image.filter(ImageFilter.Kernel((3,3), (1,1,1,0,0,0,2,0,2)))\n",
        "        # Kernel\n",
        "        return image\n",
        "\n",
        "class Salt(TransBase):\n",
        "    def setparam(self, rate=0.02):\n",
        "        self.rate = rate\n",
        "    def tranfun(self, image):\n",
        "        image = getpilimage(image)\n",
        "        num_noise = int(image.size[1] * image.size[0] * self.rate)\n",
        "        # assert len(image.split()) == 1\n",
        "        for k in range(num_noise):\n",
        "            i = int(np.random.random() * image.size[1])\n",
        "            j = int(np.random.random() * image.size[0])\n",
        "            image.putpixel((j, i), int(np.random.random() * 255))\n",
        "        return image\n",
        "\n",
        "\n",
        "class AdjustResolution(TransBase):\n",
        "    def setparam(self, max_rate=0.95,min_rate = 0.5):\n",
        "        self.max_rate = max_rate\n",
        "        self.min_rate = min_rate\n",
        "\n",
        "    def tranfun(self, image):\n",
        "        image = getpilimage(image)\n",
        "        w, h = image.size\n",
        "        rate = np.random.random()*(self.max_rate-self.min_rate)+self.min_rate\n",
        "        w2 = int(w*rate)\n",
        "        h2 = int(h*rate)\n",
        "        image = image.resize((w2, h2))\n",
        "        image = image.resize((w, h))\n",
        "        return image\n",
        "\n",
        "\n",
        "class Crop(TransBase):\n",
        "    def setparam(self, maxv=2):\n",
        "        self.maxv = maxv\n",
        "    def tranfun(self, image):\n",
        "        img = getcvimage(image)\n",
        "        h,w = img.shape[:2]\n",
        "        org = np.array([[0,np.random.randint(0,self.maxv)],\n",
        "                        [w,np.random.randint(0,self.maxv)],\n",
        "                        [0,h-np.random.randint(0,self.maxv)],\n",
        "                        [w,h-np.random.randint(0,self.maxv)]],np.float32)\n",
        "        dst = np.array([[0, 0], [w, 0], [0, h], [w, h]], np.float32)\n",
        "        M = cv2.getPerspectiveTransform(org,dst)\n",
        "        res = cv2.warpPerspective(img,M,(w,h))\n",
        "        return getpilimage(res)\n",
        "\n",
        "class Crop2(TransBase):\n",
        "    def setparam(self, maxv_h=4, maxv_w=4):\n",
        "        self.maxv_h = maxv_h\n",
        "        self.maxv_w = maxv_w\n",
        "    def tranfun(self, image_and_loc):\n",
        "        image, left, top, right, bottom = image_and_loc\n",
        "        w, h = image.size\n",
        "        left = np.clip(left,0,w-1)\n",
        "        right = np.clip(right,0,w-1)\n",
        "        top = np.clip(top, 0, h-1)\n",
        "        bottom = np.clip(bottom, 0, h-1)\n",
        "        img = getcvimage(image)\n",
        "        try:\n",
        "            # global index\n",
        "            res = getpilimage(img[top:bottom,left:right])\n",
        "            # res.save('test_imgs/crop-debug-{}.jpg'.format(index))\n",
        "            # index+=1\n",
        "            return res\n",
        "        except AttributeError as e:\n",
        "            print('error')\n",
        "            image.save('test_imgs/t.png')\n",
        "            print( left, top, right, bottom)\n",
        "\n",
        "        h = bottom - top\n",
        "        w = right - left\n",
        "        org = np.array([[left - np.random.randint(0, self.maxv_w), top + np.random.randint(-self.maxv_h, self.maxv_h//2)],\n",
        "                        [right + np.random.randint(0, self.maxv_w), top + np.random.randint(-self.maxv_h, self.maxv_h//2)],\n",
        "                        [left - np.random.randint(0, self.maxv_w), bottom - np.random.randint(-self.maxv_h, self.maxv_h//2)],\n",
        "                        [right + np.random.randint(0, self.maxv_w), bottom - np.random.randint(-self.maxv_h, self.maxv_h//2)]], np.float32)\n",
        "        dst = np.array([[0, 0], [w, 0], [0, h], [w, h]], np.float32)\n",
        "        M = cv2.getPerspectiveTransform(org,dst)\n",
        "        res = cv2.warpPerspective(img,M,(w,h))\n",
        "        return getpilimage(res)\n",
        "\n",
        "class Stretch(TransBase):\n",
        "    def setparam(self, max_rate = 1.2,min_rate = 0.8):\n",
        "        self.max_rate = max_rate\n",
        "        self.min_rate = min_rate\n",
        "\n",
        "    def tranfun(self, image):\n",
        "        image = getpilimage(image)\n",
        "        w, h = image.size\n",
        "        rate = np.random.random()*(self.max_rate-self.min_rate)+self.min_rate\n",
        "        w2 = int(w*rate)\n",
        "        image = image.resize((w2, h))\n",
        "        return image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UzKY3IJ3sj_N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "# encoding: utf-8\n",
        "\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image,ImageEnhance,ImageOps\n",
        "import numpy as np\n",
        "import codecs\n",
        "\n",
        "\n",
        "debug_idx = 0\n",
        "debug = True\n",
        "\n",
        "crop = Crop(probability=0.1)\n",
        "crop2 = Crop2(probability=1.1)\n",
        "random_contrast = RandomContrast(probability=0.1)\n",
        "random_brightness = RandomBrightness(probability=0.1)\n",
        "random_color = RandomColor(probability=0.1)\n",
        "random_sharpness = RandomSharpness(probability=0.1)\n",
        "compress = Compress(probability=0.3)\n",
        "exposure = Exposure(probability=0.1)\n",
        "rotate = Rotate(probability=0.1)\n",
        "blur = Blur(probability=0.1)\n",
        "salt = Salt(probability=0.1)\n",
        "adjust_resolution = AdjustResolution(probability=0.1)\n",
        "stretch = Stretch(probability=0.1)\n",
        "\n",
        "crop.setparam()\n",
        "crop2.setparam()\n",
        "random_contrast.setparam()\n",
        "random_brightness.setparam()\n",
        "random_color.setparam()\n",
        "random_sharpness.setparam()\n",
        "compress.setparam()\n",
        "exposure.setparam()\n",
        "rotate.setparam()\n",
        "blur.setparam()\n",
        "salt.setparam()\n",
        "adjust_resolution.setparam()\n",
        "stretch.setparam()\n",
        "\n",
        "def randomColor(image):\n",
        "    \"\"\"\n",
        "    对图像进行颜色抖动\n",
        "    :param image: PIL的图像image\n",
        "    :return: 有颜色色差的图像image\n",
        "    \"\"\"\n",
        "    random_factor = np.random.randint( 0, 31 ) / 10.  # 随机因子\n",
        "    color_image = ImageEnhance.Color( image ).enhance( random_factor )  # 调整图像的饱和度\n",
        "    random_factor = np.random.randint( 10, 21 ) / 10.  # 随机因子\n",
        "    brightness_image = ImageEnhance.Brightness( color_image ).enhance( random_factor )  # 调整图像的亮度\n",
        "    random_factor = np.random.randint( 10, 21 ) / 10.  # 随机因1子\n",
        "    contrast_image = ImageEnhance.Contrast( brightness_image ).enhance( random_factor )  # 调整图像对比度\n",
        "    random_factor = np.random.randint( 0, 31 ) / 10.  # 随机因子\n",
        "    return ImageEnhance.Sharpness( contrast_image ).enhance( random_factor )  # 调整图像锐度\n",
        "\n",
        "def randomGaussian(image, mean=0.2, sigma=0.3):\n",
        "    \"\"\"\n",
        "     对图像进行高斯噪声处理\n",
        "    :param image:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    def gaussianNoisy(im, mean=0.2, sigma=0.3):\n",
        "        \"\"\"\n",
        "        对图像做高斯噪音处理\n",
        "        :param im: 单通道图像\n",
        "        :param mean: 偏移量\n",
        "        :param sigma: 标准差\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        for _i in range( len( im ) ):\n",
        "            im[_i] += random.gauss( mean, sigma )\n",
        "        return im\n",
        "\n",
        "    # 将图像转化成数组\n",
        "    img = np.asarray( image )\n",
        "    img.flags.writeable = True  # 将数组改为读写模式\n",
        "    width, height = img.shape[:2]\n",
        "    img_r = gaussianNoisy( img[:, :, 0].flatten(), mean, sigma )\n",
        "    img_g = gaussianNoisy( img[:, :, 1].flatten(), mean, sigma )\n",
        "    img_b = gaussianNoisy( img[:, :, 2].flatten(), mean, sigma )\n",
        "    img[:, :, 0] = img_r.reshape( [width, height] )\n",
        "    img[:, :, 1] = img_g.reshape( [width, height] )\n",
        "    img[:, :, 2] = img_b.reshape( [width, height] )\n",
        "    return Image.fromarray( np.uint8( img ) )\n",
        "\n",
        "def inverse_color(image):\n",
        "    if np.random.random()<0.4:\n",
        "        image = ImageOps.invert(image)\n",
        "    return image\n",
        "\n",
        "# def data_tf(img):\n",
        "#     img = randomColor(img)\n",
        "#     # img = randomGaussian(img)\n",
        "#     img = inverse_color(img)\n",
        "#     return img\n",
        "\n",
        "def data_tf(img):\n",
        "    img = crop.process(img)\n",
        "    img = random_contrast.process(img)\n",
        "    img = random_brightness.process(img)\n",
        "    img = random_color.process(img)\n",
        "    img = random_sharpness.process(img)\n",
        "    if img.size[1]>=32:\n",
        "        img = compress.process(img)\n",
        "        img = adjust_resolution.process(img)\n",
        "        img = blur.process(img)\n",
        "    img = exposure.process(img)\n",
        "    # img = rotate.process(img)\n",
        "    img = salt.process(img)\n",
        "    img = inverse_color(img)\n",
        "    img = stretch.process(img)\n",
        "    if debug and np.random.random() < 0.001:\n",
        "        global debug_idx\n",
        "        img.save('debug_files/{:05}.jpg'.format(debug_idx))\n",
        "        debug_idx += 1\n",
        "        if debug_idx == 10000:\n",
        "            debug_idx = 0\n",
        "    return img\n",
        "\n",
        "def data_tf_fullimg(img,loc):\n",
        "    left, top, right, bottom = loc\n",
        "    img = crop2.process([img, left, top, right, bottom])\n",
        "    img = random_contrast.process(img)\n",
        "    img = random_brightness.process(img)\n",
        "    img = random_color.process(img)\n",
        "    img = random_sharpness.process(img)\n",
        "    img = compress.process(img)\n",
        "    img = exposure.process(img)\n",
        "    # img = rotate.process(img)\n",
        "    img = blur.process(img)\n",
        "    img = salt.process(img)\n",
        "    # img = inverse_color(img)\n",
        "    img = adjust_resolution.process(img)\n",
        "    img = stretch.process(img)\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self,info_filename,train=True, transform=data_tf,target_transform=None,remove_blank = False):\n",
        "        super(Dataset, self).__init__()\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.info_filename = info_filename\n",
        "        if isinstance(self.info_filename,str):\n",
        "            self.info_filename = [self.info_filename]\n",
        "        self.train = train\n",
        "        self.files = list()\n",
        "        self.labels = list()\n",
        "        for info_name in self.info_filename:\n",
        "            with open(info_name) as f:\n",
        "                content = f.readlines()\n",
        "                for line in content:\n",
        "                    if ' ' in line:\n",
        "                        parts = line.split(' ')\n",
        "                        if len(parts) != 2:\n",
        "                            print(f\"格式错误: {line}\")\n",
        "                        else:\n",
        "                            fname, label = parts\n",
        "                            if remove_blank:\n",
        "                                label = label.strip()\n",
        "                            else:\n",
        "                                label = ' ' + label.strip() + ' '\n",
        "                            self.files.append(fname)\n",
        "                            self.labels.append(label)\n",
        "\n",
        "    def name(self):\n",
        "        return 'MyDataset'\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # print(self.files[index])\n",
        "        # print(self.files[index])\n",
        "        img = Image.open(self.files[index])\n",
        "        if self.transform is not None:\n",
        "            img = self.transform( img )\n",
        "        img = img.convert('L')\n",
        "        # target = torch.zeros(len(self.labels_min))\n",
        "        # target[self.labels_min.index(self.labels[index])] = 1\n",
        "        label = self.labels[index]\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform( label )\n",
        "        return (img,label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "class MyDatasetPro(Dataset):\n",
        "    def __init__(self, info_filename_txtline=list(), info_filename_fullimg=list(), train=True, txtline_transform=data_tf,\n",
        "                 fullimg_transform = data_tf_fullimg, target_transform=None):\n",
        "        super(Dataset, self).__init__()\n",
        "        self.txtline_transform = txtline_transform\n",
        "        self.fullimg_transform = fullimg_transform\n",
        "        self.target_transform = target_transform\n",
        "        self.info_filename_txtline = info_filename_txtline\n",
        "        self.info_filename_fullimg = info_filename_fullimg\n",
        "        if isinstance(self.info_filename_txtline,str):\n",
        "            self.info_filename_txtline = [self.info_filename_txtline]\n",
        "        if isinstance(self.info_filename_fullimg,str):\n",
        "            self.info_filename_fullimg = [self.info_filename_fullimg]\n",
        "        self.train = train\n",
        "        self.files = list()\n",
        "        self.labels = list()\n",
        "        self.locs = list()\n",
        "        for info_name in self.info_filename_txtline:\n",
        "            with open(info_name) as f:\n",
        "                content = f.readlines()\n",
        "                for line in content:\n",
        "                    fname,label = line.split('g')\n",
        "                    fname += 'g'\n",
        "                    label = label.replace('\\r','').replace('\\n','')\n",
        "                    self.files.append(fname)\n",
        "                    self.labels.append(label)\n",
        "        self.txtline_len = len(self.labels)\n",
        "        for info_name in self.info_filename_fullimg:\n",
        "            with open(info_name) as f:\n",
        "                content = f.readlines()\n",
        "                for line in content:\n",
        "                    fname,label,left, top, right, bottom = line.strip().split('\\t')\n",
        "                    self.files.append(fname)\n",
        "                    self.labels.append(label)\n",
        "                    self.locs.append([int(left),int(top),int(right),int(bottom)])\n",
        "        print(len(self.labels),len(self.files))\n",
        "    def name(self):\n",
        "        return 'MyDatasetPro'\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # print(self.files[index])\n",
        "        label = self.labels[index]\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "        img = Image.open(self.files[index])\n",
        "        if index>=self.txtline_len:\n",
        "            # print('fullimg:{}'.format(self.files[index]),img.size)\n",
        "            img = self.fullimg_transform(img,self.locs[index-self.txtline_len])\n",
        "            if index%100 == 0:\n",
        "                img.save('test_imgs/debug-{}-{}.jpg'.format(index,label.strip()))  #debug\n",
        "        else:\n",
        "            if self.txtline_transform is not None:\n",
        "                img = self.txtline_transform(img)\n",
        "        img = img.convert('L')\n",
        "        # target = torch.zeros(len(self.labels_min))\n",
        "        # target[self.labels_min.index(self.labels[index])] = 1\n",
        "        return (img,label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "class resizeNormalize2(object):\n",
        "\n",
        "    def __init__(self, size, interpolation=Image.LANCZOS):\n",
        "        self.size = size\n",
        "        self.interpolation = interpolation\n",
        "        self.toTensor = transforms.ToTensor()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = img.resize(self.size, self.interpolation)\n",
        "        img = self.toTensor(img)\n",
        "        img.sub_(0.5).div_(0.5)\n",
        "        return img\n",
        "\n",
        "class resizeNormalize(object):\n",
        "    def __init__(self, size, interpolation=Image.LANCZOS,is_test=False):\n",
        "        self.size = size\n",
        "        self.interpolation = interpolation\n",
        "        self.toTensor = transforms.ToTensor()\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w,h = self.size\n",
        "        w0 = img.size[0]\n",
        "        h0 = img.size[1]\n",
        "        if w<=(w0/h0*h):\n",
        "            img = img.resize(self.size, self.interpolation)\n",
        "            img = self.toTensor(img)\n",
        "            img.sub_(0.5).div_(0.5)\n",
        "        else:\n",
        "            w_real = int(w0/h0*h)\n",
        "            img = img.resize((w_real,h), self.interpolation)\n",
        "            img = self.toTensor(img)\n",
        "            img.sub_(0.5).div_(0.5)\n",
        "            start = random.randint(0,w-w_real-1)\n",
        "            if self.is_test:\n",
        "                start = 5\n",
        "                w+=10\n",
        "            tmp = torch.zeros([img.shape[0], h, w])+0.5\n",
        "            tmp[:,:,start:start+w_real] = img\n",
        "            img = tmp\n",
        "        return img\n",
        "\n",
        "class randomSequentialSampler(sampler.Sampler):\n",
        "\n",
        "    def __init__(self, data_source, batch_size):\n",
        "        self.num_samples = len(data_source)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        n_batch = len(self) // self.batch_size\n",
        "        tail = len(self) % self.batch_size\n",
        "        index = torch.LongTensor(len(self)).fill_(0)\n",
        "        for i in range(n_batch):\n",
        "            random_start = random.randint(0, len(self) - self.batch_size)\n",
        "            batch_index = random_start + torch.range(0, self.batch_size - 1)\n",
        "            index[i * self.batch_size:(i + 1) * self.batch_size] = batch_index\n",
        "        # deal with tail\n",
        "        if tail:\n",
        "            random_start = random.randint(0, len(self) - self.batch_size)\n",
        "            tail_index = random_start + torch.range(0, tail - 1)\n",
        "            index[(i + 1) * self.batch_size:] = tail_index\n",
        "\n",
        "        return iter(index)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "\n",
        "class alignCollate(object):\n",
        "\n",
        "    def __init__(self, imgH=32, imgW=100, keep_ratio=False, min_ratio=1):\n",
        "        self.imgH = imgH\n",
        "        self.imgW = imgW\n",
        "        self.keep_ratio = keep_ratio\n",
        "        self.min_ratio = min_ratio\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        images, labels = zip(*batch)\n",
        "\n",
        "        imgH = self.imgH\n",
        "        imgW = self.imgW\n",
        "        if self.keep_ratio:\n",
        "            ratios = []\n",
        "            for image in images:\n",
        "                w, h = image.size\n",
        "                ratios.append(w / float(h))\n",
        "            ratios.sort()\n",
        "            max_ratio = ratios[-1]\n",
        "            imgW = int(np.floor(max_ratio * imgH))\n",
        "            imgW = max(imgH * self.min_ratio, imgW)  # assure imgH >= imgW\n",
        "\n",
        "        transform = resizeNormalize((imgW, imgH))\n",
        "        images = [transform(image) for image in images]\n",
        "        images = torch.cat([t.unsqueeze(0) for t in images], 0)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XiIL0Rlast59"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "# encoding: utf-8\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from collections.abc import Iterable\n",
        "from datetime import datetime\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def get_acc(output, label):\n",
        "    total = output.shape[0]\n",
        "    _, pred_label = output.max(1)\n",
        "    num_correct = (pred_label == label).sum().item()\n",
        "    # print( pred_label.data.cpu().numpy() )\n",
        "    # print( label.data.cpu().numpy() )\n",
        "    return 1.0*num_correct / total\n",
        "\n",
        "def adjust_learning_rate(optimizer,decay_rate = 0.97):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr']*decay_rate\n",
        "\n",
        "def train(net, train_data, valid_data, num_epochs, optimizer, criterion,saver_freq = 50,saver_prefix = 'vgg16'):\n",
        "    if torch.cuda.is_available():\n",
        "        net = net.cuda()\n",
        "    prev_time = datetime.now()\n",
        "    best_acc = 0.98\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        net = net.train()\n",
        "        for im, label in train_data:\n",
        "            # print(label)\n",
        "            if torch.cuda.is_available():\n",
        "                im = Variable(im.cuda())  # (bs, 3, h, w)\n",
        "                label = Variable(label.cuda())  # (bs, h, w)\n",
        "            else:\n",
        "                im = Variable(im)\n",
        "                label = Variable(label)\n",
        "            # forward\n",
        "            output = net(im)\n",
        "            loss = criterion(output, label)\n",
        "            # backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_acc += get_acc(output, label)\n",
        "\n",
        "        cur_time = datetime.now()\n",
        "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
        "        m, s = divmod(remainder, 60)\n",
        "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
        "        if valid_data is not None:\n",
        "            valid_loss = 0\n",
        "            valid_acc = 0\n",
        "            net = net.eval()\n",
        "            for im, label in valid_data:\n",
        "                if torch.cuda.is_available():\n",
        "                    im = Variable(im.cuda(), volatile=True)\n",
        "                    label = Variable(label.cuda(), volatile=True)\n",
        "                else:\n",
        "                    im = Variable(im, volatile=True)\n",
        "                    label = Variable(label, volatile=True)\n",
        "                output = net(im)\n",
        "                loss = criterion(output, label)\n",
        "                valid_loss += loss.item()\n",
        "                valid_acc += get_acc(output, label)\n",
        "            epoch_str = (\n",
        "                \"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, \"\n",
        "                % (epoch, train_loss / len(train_data),\n",
        "                   train_acc / len(train_data), valid_loss / len(valid_data),\n",
        "                   valid_acc / len(valid_data)))\n",
        "            if valid_acc / len(valid_data)>best_acc:\n",
        "                best_acc = valid_acc / len(valid_data)\n",
        "                torch.save( net.state_dict(), 'models/{}-{}-{}-0819-model-db.pth'.format(saver_prefix ,epoch + 1,int(best_acc*1000) ) )\n",
        "        else:\n",
        "            epoch_str = (\"Epoch %d. Train Loss: %f, Train Acc: %f, \" %\n",
        "                         (epoch, train_loss / len(train_data),\n",
        "                          train_acc / len(train_data)))\n",
        "        prev_time = cur_time\n",
        "        print(epoch_str + time_str)\n",
        "        # if (epoch+1)%saver_freq == 0:\n",
        "        #     # torch.save(net,'models/vgg-16-'+str(epoch+1)+'-model.pth')\n",
        "        #     # another weight saver method\n",
        "        #     torch.save(net.state_dict(),'models/{}-{}-0711-model.pth'.format(saver_prefix, epoch+1))\n",
        "        adjust_learning_rate(optimizer)\n",
        "\n",
        "class strLabelConverter(object):\n",
        "    \"\"\"Convert between str and label.\n",
        "\n",
        "    NOTE:\n",
        "        Insert `blank` to the alphabet for CTC.\n",
        "\n",
        "    Args:\n",
        "        alphabet (str): set of the possible characters.\n",
        "        ignore_case (bool, default=True): whether or not to ignore all of the case.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alphabet, ignore_case=False):\n",
        "        self._ignore_case = ignore_case\n",
        "        if self._ignore_case:\n",
        "            alphabet = alphabet.lower()\n",
        "        self.alphabet = alphabet\n",
        "        self.alphabet.append(ord('_'))  # for `-1` index\n",
        "        # print(self.alphabet)\n",
        "\n",
        "        self.dict = {}\n",
        "        for i, char in enumerate(alphabet):\n",
        "            # NOTE: 0 is reserved for 'blank' required by wrap_ctc\n",
        "            self.dict[char] = i + 1\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"Support batch or single str.\n",
        "\n",
        "        Args:\n",
        "            text (str or list of str): texts to convert.\n",
        "\n",
        "        Returns:\n",
        "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
        "            torch.IntTensor [n]: length of each text.\n",
        "        \"\"\"\n",
        "        # print(text)\n",
        "        try:\n",
        "            if isinstance(text, str):\n",
        "                # for char in text:\n",
        "                #     print(char)\n",
        "                text = [\n",
        "                    self.dict[ord(char.lower() if self._ignore_case else char)]\n",
        "                    for char in text# if char in self.dict.keys()\n",
        "                ]\n",
        "                length = [len(text)]\n",
        "            elif isinstance(text, Iterable):\n",
        "                length = [len(s) for s in text]\n",
        "                text = ''.join(text)\n",
        "                text, _ = self.encode(text)\n",
        "        except KeyError as e:\n",
        "            # print(text)\n",
        "            print(e)\n",
        "            for ch in text:\n",
        "                if ord(ch) not in self.dict.keys():\n",
        "                    print('Not Covering Char: {} - {}'.format(ch,ord(ch)))\n",
        "        return (torch.IntTensor(text), torch.IntTensor(length))\n",
        "\n",
        "    def decode(self, t, length, raw=False):\n",
        "        \"\"\"Decode encoded texts back into strs.\n",
        "\n",
        "        Args:\n",
        "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
        "            torch.IntTensor [n]: length of each text.\n",
        "\n",
        "        Raises:\n",
        "            AssertionError: when the texts and its length does not match.\n",
        "\n",
        "        Returns:\n",
        "            text (str or list of str): texts to convert.\n",
        "        \"\"\"\n",
        "        if length.numel() == 1:\n",
        "            length = length[0]\n",
        "            assert t.numel() == length, \"text with length: {} does not match declared length: {}\".format(t.numel(), length)\n",
        "            if raw:\n",
        "                return ''.join([chr(self.alphabet[i - 1]) for i in t])\n",
        "            else:\n",
        "                char_list = []\n",
        "                for i in range(length):\n",
        "                    if t[i] != 0 and (not (i > 0 and t[i - 1] == t[i])):\n",
        "                        char_list.append(chr(self.alphabet[t[i] - 1]))\n",
        "\n",
        "                return ''.join(char_list)\n",
        "        else:\n",
        "            # batch mode\n",
        "            assert t.numel() == length.sum(), \"texts with length: {} does not match declared length: {}\".format(t.numel(), length.sum())\n",
        "            texts = []\n",
        "            index = 0\n",
        "            for i in range(length.numel()):\n",
        "                l = length[i]\n",
        "                texts.append(\n",
        "                    self.decode(\n",
        "                        t[index:index + l], torch.IntTensor([l]), raw=raw))\n",
        "                index += l\n",
        "            return texts\n",
        "\n",
        "\n",
        "class averager(object):\n",
        "    \"\"\"Compute average for `torch.Variable` and `torch.Tensor`. \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def add(self, v):\n",
        "        if isinstance(v, Variable):\n",
        "            count = v.data.numel()\n",
        "            v = v.data.sum()\n",
        "        elif isinstance(v, torch.Tensor):\n",
        "            count = v.numel()\n",
        "            v = v.sum()\n",
        "\n",
        "        self.n_count += count\n",
        "        self.sum += v\n",
        "\n",
        "    def reset(self):\n",
        "        self.n_count = 0\n",
        "        self.sum = 0\n",
        "\n",
        "    def val(self):\n",
        "        res = 0\n",
        "        if self.n_count != 0:\n",
        "            res = self.sum / float(self.n_count)\n",
        "        return res\n",
        "\n",
        "\n",
        "def oneHot(v, v_length, nc):\n",
        "    batchSize = v_length.size(0)\n",
        "    maxLength = v_length.max()\n",
        "    v_onehot = torch.FloatTensor(batchSize, maxLength, nc).fill_(0)\n",
        "    acc = 0\n",
        "    for i in range(batchSize):\n",
        "        length = v_length[i]\n",
        "        label = v[acc:acc + length].view(-1, 1).long()\n",
        "        v_onehot[i, :length].scatter_(1, label, 1.0)\n",
        "        acc += length\n",
        "    return v_onehot\n",
        "\n",
        "\n",
        "def loadData(v, data):\n",
        "    v.data.resize_(data.size()).copy_(data)\n",
        "\n",
        "\n",
        "def prettyPrint(v):\n",
        "    print('Size {0}, Type: {1}'.format(str(v.size()), v.data.type()))\n",
        "    print('| Max: %f | Min: %f | Mean: %f' % (v.max().item(), v.min().item(),\n",
        "                                              v.mean().item()))\n",
        "\n",
        "\n",
        "def assureRatio(img):\n",
        "    \"\"\"Ensure imgH <= imgW.\"\"\"\n",
        "    b, c, h, w = img.size()\n",
        "    if h > w:\n",
        "        main = nn.UpsamplingBilinear2d(size=(h, h), scale_factor=None)\n",
        "        img = main(img)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "bPgk0DtJtFO2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "alphabet = alphabet_v2\n",
        "converter = strLabelConverter(alphabet.copy())\n",
        "\n",
        "\n",
        "def val_model(infofile,model,gpu,log_file = '0625.log'):\n",
        "    h = open('log/{}'.format(log_file),'w')\n",
        "    with open(infofile) as f:\n",
        "        content = f.readlines()\n",
        "        num_all = 0\n",
        "        num_correct = 0\n",
        "\n",
        "        for line in content:\n",
        "            if ' ' in line:\n",
        "                fname, label = line.split(' ')\n",
        "            else:\n",
        "                fname, label = line.split('g:')\n",
        "                fname += 'g'\n",
        "            label = label.replace('\\r', '').replace('\\n', '')\n",
        "            img = cv2.imread(fname)\n",
        "            res = val_on_image(img,model,gpu)\n",
        "            res = res.strip()\n",
        "            label = label.strip()\n",
        "            if res == label:\n",
        "                num_correct+=1\n",
        "            else:\n",
        "                print('filename:{}\\npred  :{}\\ntarget:{}'.format(fname, res, label))\n",
        "                h.write('filename:{}\\npred  :{}\\ntarget:{}\\n'.format(fname,res, label))\n",
        "            # else:\n",
        "            #     # new_name = saved_path + fname.split('/')[-1]\n",
        "            #     # shutil.copyfile(fname, new_name)\n",
        "            #     wrong_results.append('res:{} / label:{}'.format(res,label))\n",
        "            num_all+=1\n",
        "    h.write('ocr_correct: {}/{}/{}\\n'.format(num_correct,num_all,num_correct/num_all))\n",
        "    print(num_correct/num_all)\n",
        "    h.close()\n",
        "    return num_correct, num_all\n",
        "\n",
        "def val_on_image(img,model,gpu):\n",
        "    imgH = imgH\n",
        "    h,w = img.shape[:2]\n",
        "    imgW = imgH*w//h\n",
        "\n",
        "    transformer = resizeNormalize((imgW, imgH), is_test=True)\n",
        "    img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB )\n",
        "    image = Image.fromarray(np.uint8(img)).convert('L')\n",
        "    image = transformer( image )\n",
        "    if gpu:\n",
        "        image = image.cuda()\n",
        "    image = image.view( 1, *image.size() )\n",
        "    image = Variable( image )\n",
        "\n",
        "    model.eval()\n",
        "    preds = model( image )\n",
        "\n",
        "    preds = F.log_softmax(preds,2)\n",
        "    conf, preds = preds.max( 2 )\n",
        "    preds = preds.transpose( 1, 0 ).contiguous().view( -1 )\n",
        "\n",
        "    preds_size = Variable( torch.IntTensor( [preds.size( 0 )] ) )\n",
        "    # raw_pred = converter.decode( preds.data, preds_size.data, raw=True )\n",
        "    sim_pred = converter.decode( preds.data, preds_size.data, raw=False )\n",
        "    return sim_pred\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S1tGh_n-tNGl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import random\n",
        "import torch\n",
        "# import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "# from warpctc_pytorch import CTCLoss\n",
        "from torch.nn import CTCLoss\n",
        "imgW = 800\n",
        "alphabet = alphabet_v2\n",
        "nclass = len(alphabet) + 1\n",
        "saved_model_prefix = 'E-Point-Super-01'\n",
        "#config.train_infofile = ['path_to_train_infofile1.txt','path_to_train_infofile2.txt']\n",
        "train_infofile = ['/content/sample_data/train_crnn/train_data/train/train-1.txt']\n",
        "val_infofile = '/content/sample_data/train_crnn/train_data/train/test.txt'\n",
        "keep_ratio = True\n",
        "use_log = True\n",
        "pretrained_model = '/content/sample_data/train_crnn/crnn_models/E-Point-Super.pth'\n",
        "batchSize = 1\n",
        "workers = 0\n",
        "adam = True\n",
        "# config.lr = 0.00003\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "\n",
        "# 数据集360W：https://pan.baidu.com/s/1ufYbnZAZ1q0AlK7yZ08cvQ\n",
        "#https://github.com/Sanster/text_renderer\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "log_filename = os.path.join('log/','loss_acc-'+saved_model_prefix + '.log')\n",
        "if not os.path.exists('debug_files'):\n",
        "    os.mkdir('debug_files')\n",
        "if not os.path.exists(saved_model_dir):\n",
        "    os.mkdir(saved_model_dir)\n",
        "if use_log and not os.path.exists('log'):\n",
        "    os.mkdir('log')\n",
        "if use_log and os.path.exists(log_filename):\n",
        "    os.remove(log_filename)\n",
        "if experiment is None:\n",
        "    experiment = 'expr'\n",
        "if not os.path.exists(experiment):\n",
        "    os.mkdir(experiment)\n",
        "\n",
        "manualSeed = random.randint(1, 10000)  # fix seed\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "np.random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "\n",
        "# cudnn.benchmark = True\n",
        "train_dataset = MyDataset(info_filename=train_infofile)\n",
        "assert train_dataset\n",
        "if not random_sample:\n",
        "    sampler = randomSequentialSampler(train_dataset, batchSize)\n",
        "else:\n",
        "    sampler = None\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batchSize,\n",
        "    shuffle=True, sampler=sampler,\n",
        "    num_workers=int(workers),\n",
        "    collate_fn=alignCollate(imgH=imgH, imgW=imgW, keep_ratio=keep_ratio))\n",
        "\n",
        "test_dataset = MyDataset(\n",
        "    info_filename=val_infofile, transform=resizeNormalize((imgW, imgH), is_test=True))\n",
        "\n",
        "converter = strLabelConverter(alphabet)\n",
        "criterion = CTCLoss(reduction='sum',zero_infinity=True)\n",
        "# criterion = CTCLoss()\n",
        "best_acc = 0.9\n",
        "\n",
        "\n",
        "# custom weights initialization called on crnn\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "crnn = CRNN(imgH, nc, nclass, nh)\n",
        "\n",
        "if pretrained_model!='' and os.path.exists(pretrained_model):\n",
        "    print('loading pretrained model from %s' % pretrained_model)\n",
        "    crnn.load_state_dict(torch.load(pretrained_model))\n",
        "else:\n",
        "    crnn.apply(weights_init)\n",
        "\n",
        "print(crnn)\n",
        "\n",
        "# image = torch.FloatTensor(config.batchSize, 3, config.imgH, config.imgH)\n",
        "# text = torch.IntTensor(config.batchSize * 5)\n",
        "# length = torch.IntTensor(config.batchSize)\n",
        "device = torch.device('cpu')\n",
        "if cuda:\n",
        "    crnn.cuda()\n",
        "    # crnn = torch.nn.DataParallel(crnn, device_ids=range(opt.ngpu))\n",
        "    # image = image.cuda()\n",
        "    device = torch.device('cuda:0')\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "# image = Variable(image)\n",
        "# text = Variable(text)\n",
        "# length = Variable(length)\n",
        "\n",
        "# loss averager\n",
        "loss_avg = averager()\n",
        "\n",
        "# setup optimizer\n",
        "if adam:\n",
        "    optimizer = optim.Adam(crnn.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "elif adadelta:\n",
        "    optimizer = optim.Adadelta(crnn.parameters(), lr=lr)\n",
        "else:\n",
        "    optimizer = optim.RMSprop(crnn.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "def val(net, dataset, criterion, max_iter=100):\n",
        "    print('Start val')\n",
        "    for p in net.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    num_correct,  num_all = val_model(val_infofile,net,True,log_file='compare-'+saved_model_prefix+'.log')\n",
        "    accuracy = num_correct / num_all\n",
        "\n",
        "    print('ocr_acc: %f' % (accuracy))\n",
        "    if use_log:\n",
        "        with open(log_filename, 'a') as f:\n",
        "            f.write('ocr_acc:{}\\n'.format(accuracy))\n",
        "    global best_acc\n",
        "    if accuracy > best_acc:\n",
        "        best_acc = accuracy\n",
        "        torch.save(crnn.state_dict(), '{}/{}_{}_{}.pth'.format(saved_model_dir, saved_model_prefix, epoch,\n",
        "                                                               int(best_acc * 1000)))\n",
        "    torch.save(crnn.state_dict(), '{}/{}.pth'.format(saved_model_dir, saved_model_prefix))\n",
        "\n",
        "\n",
        "def trainBatch(net, criterion, optimizer):\n",
        "    data = next(train_iter)\n",
        "    cpu_images, cpu_texts = data\n",
        "    batch_size = cpu_images.size(0)\n",
        "    image = cpu_images.to(device)\n",
        "\n",
        "    text, length = converter.encode(cpu_texts)\n",
        "    # utils.loadData(text, t)\n",
        "    # utils.loadData(length, l)\n",
        "\n",
        "    preds = net(image)  # seqLength x batchSize x alphabet_size\n",
        "    preds_size = Variable(torch.IntTensor([preds.size(0)] * batch_size))  # seqLength x batchSize\n",
        "    cost = criterion(preds.log_softmax(2).cpu(), text, preds_size, length) / batch_size\n",
        "    if torch.isnan(cost):\n",
        "        print(batch_size,cpu_texts)\n",
        "    else:\n",
        "        net.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "    return cost\n",
        "\n",
        "\n",
        "for epoch in range(niter):\n",
        "    loss_avg.reset()\n",
        "    print('epoch {}....'.format(epoch))\n",
        "    train_iter = iter(train_loader)\n",
        "    i = 0\n",
        "    n_batch = len(train_loader)\n",
        "    while i < len(train_loader):\n",
        "        for p in crnn.parameters():\n",
        "            p.requires_grad = True\n",
        "        crnn.train()\n",
        "        cost = trainBatch(crnn, criterion, optimizer)\n",
        "        print('epoch: {} iter: {}/{} Train loss: {:.3f}'.format(epoch, i, n_batch, cost.item()))\n",
        "        loss_avg.add(cost)\n",
        "        loss_avg.add(cost)\n",
        "        i += 1\n",
        "    print('Train loss: %f' % (loss_avg.val()))\n",
        "    if use_log:\n",
        "        with open(log_filename, 'a') as f:\n",
        "            f.write('{}\\n'.format(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')))\n",
        "            f.write('train_loss:{}\\n'.format(loss_avg.val()))\n",
        "\n",
        "    val(crnn, test_dataset, criterion)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "wTzmd7WTtsDF",
        "outputId": "be0cba66-bb33-4960-8464-4c9b0b32f2c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  7067\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0xb8 in position 28: invalid start byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-57a0302af4b2>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# cudnn.benchmark = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_infofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrandom_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3709a1f3e9e5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, info_filename, train, transform, target_transform, remove_blank)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minfo_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb8 in position 28: invalid start byte"
          ]
        }
      ]
    }
  ]
}